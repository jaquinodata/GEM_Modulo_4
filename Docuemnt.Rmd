---
title: "Untitled"
author: "Jorge Luis Aquino Olmos"
date: "2024-03-12"
output: pdf_document
---
# Modelos de Regresión
Los modelos de regresión son una clase de técnicas estadísticas utilizadas para predecir el valor de una variable dependiente basándose en una o varias variables indpendientes. Las variables independientes, también llamadas predictoras o variables explicativas, son aquellas que se usan para realizar la predicción.

Existen varios tipos de modelos de regresión, cada uno diseñado para diferentes tipos de datos y situaciones, algunos de los tipos más comunes de modelos de regresión:

1. **Regresión Lineal simple**: Es el tipo más básico de modelo de regresión. Se utiliza cuando hay una relación lineal entre una variable independiente y una variable dependiente. La ecuación de regresión lineal simple tiene la forma:
$$ y = \beta_0 + \beta_1x + \epsilon$$
donde y es la variable dependiente, x es la variable independiente $\beta_0$ es el intercepto, $\beta_1$ es la pendiente y $\epsilon$ es el término de error.


2. **Regresión lineal múltiple**:  Este modelo se utiliza cuando hay más de una variable independiente que influye en la variable dependiente. La ecuación de regresión lineal múltiple tiene la forma
$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_nx_n + \epsilon\ $$donde $\beta_0, \beta_1, ... ,\beta_n$ son los coeficientes que se estiman a partir de los datos $ x_1, x_2, ..., x_n $ y $\epsilon$ es el término de error.

3. **Regresión polinomial**: Este tipo de regresión se utiliza cuando la relación entre la variable independiente y la variable dependiente no es lineal. Se ajusta una curva polinomial a los datos, lo que permite capturar relaciones más complejas. Por ejemplo, una regresión polinomial de segundo grado tiene la forma
$$ y=\beta_0+\beta_1x+\beta_2x^2+\epsilon $$

4. **Regresión Logística**:
  La regresión logística, también conocida como "modelo logit", es una técnica estadística utilizada para predecir variables categóricas a partir de variables predictoras. A diferencia de la regresión lineal, que se emplea para predecir valores continuos, la regresión logística se aplica cuando la variable dependiente es finita o categórica. Esta variable puede ser binaria, como sí/no o 1/0, lo que se conoce como regresión binaria, o puede tener múltiples categorías, como A, B, C o D, lo que se conoce como regresión multinomial.
  
### Estimación de Coeficientes mediante Mínimos Cuadrados Ordinarios

Los Mínimos Cuadrados Ordinarios (OLS, por sus siglas en inglés) es un método comúnmente utilizado para estimar los parámetros desconocidos en modelos de regresión. El objetivo es encontrar los coeficientes que minimizan la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo.

Para el caso de la regresión lineal simple, la estimación de los coeficientes se realiza de la siguiente manera:

Dado un conjunto de datos ${(x_i, y_i)}$ para $i = 1, 2, ..., n$, donde $x_i$ es la variable independiente y $y_i$ es la variable dependiente, la estimación de los coeficientes $\beta_0$ y $\beta_1$ se obtiene minimizando la función de pérdida, que en este caso es la suma de los cuadrados de los residuos (errores), denotada por $SSR$:

\begin{equation}
SSR = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2
\end{equation}

Para encontrar los valores de $\beta_0$ y $\beta_1$ que minimizan $SSR$, se derivan parcialmente $SSR$ con respecto a $\beta_0$ y $\beta_1$, se igualan a cero y se resuelven las ecuaciones resultantes. Esto conduce a las llamadas ecuaciones normales:

\begin{align}
\frac{\partial SSR}{\partial \beta_0} &= -2 \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i)) = 0 \\
\frac{\partial SSR}{\partial \beta_1} &= -2 \sum_{i=1}^{n} x_i(y_i - (\beta_0 + \beta_1 x_i)) = 0
\end{align}

Resolviendo estas ecuaciones, se obtienen las estimaciones de los coeficientes $\beta_0$ y $\beta_1$:

\begin{align}
\hat{\beta_1} &= \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} \\
\hat{\beta_0} &= \bar{y} - \hat{\beta_1}\bar{x}
\end{align}

donde $\bar{x}$ y $\bar{y}$ son las medias de las variables independiente y dependiente, respectivamente.

Para la regresión lineal múltiple y otros tipos de regresión, las ecuaciones normales se generalizan en forma matricial:

\begin{equation}
\mathbf{\hat{\beta}} = (\mathbf{X}^\intercal \mathbf{X})^{-1} \mathbf{X}^\intercal \mathbf{y}
\end{equation}

donde $\mathbf{X}$ es una matriz de diseño que contiene las variables independientes, $\mathbf{y}$ es un vector de la variable dependiente, y $\mathbf{\hat{\beta}}$ son los coeficientes estimados.

### Modelización de Retención de Empleados y Ganancias de Tiendas en Store24

El objetivo de este estudio es comprender cómo la retención de empleados en las tiendas de Store24 influye en sus ganancias. Utilizando datos del año fiscal 2000, exploraremos diversas variables relacionadas con la gestión de recursos humanos, características de ubicación de la tienda y datos demográficos para determinar su impacto en la utilidad de las tiendas.

Nuestra variable objetivo será la "Utilidad del año fiscal 2000 antes de asignación de gastos indirectos corporativos, alquiler y depreciación", que refleja las ganancias de cada tienda. Consideraremos una serie de variables predictoras, como la antigüedad promedio de los gerentes y el personal, la competencia en la ubicación de la tienda, la densidad de población circundante y características de la tienda, como su horario de apertura y su ubicación residencial o industrial.

A través de técnicas de regresión, exploraremos la relación entre estas variables y las ganancias de las tiendas, con el objetivo de identificar áreas de oportunidad para mejorar la retención de empleados y, en última instancia, aumentar las ganancias de Store24.

### Variables que haran parte de estudio. 

| Variable   | Descripción                                                                                                                                      |
|------------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| Sales      | Ventas del año fiscal 2000                                                                                                                       |
| Profit     | Utilidad del año fiscal 2000 antes de asignación de gastos indirectos corporativos, alquiler y depreciación                                      |
| MTenure    | Antigüedad promedio en el puesto del gerente durante el año fiscal 2000 donde la tenencia se define como el número de meses de experiencia en Store24 |
| CTenure    | Antigüedad promedio en el puesto del personal durante el año fiscal 2000 donde la tenencia se define como el número de meses de experiencia en Store24 |
| Comp       | Número de competidores por 10,000 personas dentro de un radio de 1/2 milla                                                                       |
| Pop        | Población dentro de un radio de 1/2 milla                                                                                                       |
| Visibility | Calificación de 5 puntos en visibilidad del frente de la tienda, siendo 5 la más alta                                                           |
| PedCount   | Calificación de 5 puntos sobre el volumen de tráfico de peatones, siendo 5 el más alto                                                         |
| Hours24    | Indicador de si la tienda abre o no 24 horas                                                                                                    |
| Res        | Indicador de ubicado en zona residencial vs. industrial                                                                                           |
| CrewSkill  | Habilidad del equipo                                                                                                                             |
| MgrSkill   | Habilidad de gestión                                                                                                                             |
| ServQual   | Medición de calidad de servicio                                                                                                                  |


Como podemos observar el conjunto de datos que servirán para realizar nuestro modelo contienen información financieras, otras que describen la gestión del recurso humano y variables de ubicación de las tiendas. 

### Lectura de los datos
  
  
```{r include=FALSE, warning=FALSE}
# install.packages("kntr")
# install.packages("corrgram")
# install.packages("caTools")
# install.packages("kableExtra")
# install.packages("formattable")
# install.packages("caret")
library(readxl)
library(tidyverse)
library(dplyr)
library(knitr)
library(ggplot2)
library(gridExtra)
library(corrgram)
library(caTools)
library(kableExtra)
library(formattable)
library(caret)
library(corrplot)

```
```{r echo=FALSE, warning= FALSE}
# Cargar los datos desde el archivo Excel
datos <- read_excel("../store24_data.xls", sheet = "Store24")

# Mostrar los datos utilizando la función kable
kable(head(datos, 10))

```
En nuestro conjunto de datos, contamos con varias variables que representan la valoración de cualidades específicas en un contexto particular. Estas variables, denominadas Visibility, PedCount, Res y Hours24, están diseñadas para capturar la evaluación de ciertas características relevantes para el desempeño y la operación de las tiendas. Cada una de estas variables de valoración de cualidades tiene un conjunto discreto de valores que representan diferentes niveles de la cualidad evaluada.
Al ser variables categóricas ordinales, estas valoraciones no solo nos brindan una comprensión de la situación actual de las tiendas en términos de las cualidades evaluadas, sino que también nos permiten identificar tendencias, patrones y áreas de mejora en nuestra operación y gestión.

A continuación, se presenta un resumen estadístico de las variables numéricas en nuestro conjunto de datos. Este resumen proporciona una visión general de la distribución y variabilidad de cada variable, lo que nos ayuda a comprender mejor la naturaleza de nuestros datos y a identificar posibles patrones o tendencias.


```{r  echo=FALSE, warning= FALSE}
# Resumen estadístico de los datos con la función skim del paquete skimr 
# install.packages("skimr")
library(skimr)
select(datos, -c(store, Visibility, PedCount, Res, Hours24 )) |>
  skim() |>
  yank("numeric")

```
Nuestro resumen estadístico incluye las siguientes estadísticas para cada una de las nueve variables numéricas en nuestro conjunto de datos:

**Media (mean)**: La media es el promedio de los valores de la variable. Indica el valor central alrededor del cual tienden a agruparse los datos.

**Desviación estándar (sd)**: La desviación estándar mide la dispersión de los datos alrededor de la media. Una desviación estándar más alta indica una mayor dispersión de los datos.

**Valores mínimos y máximos (p0 y p100)**: Estos valores representan los límites inferiores y superiores del rango de los datos, respectivamente.

**Cuartiles (p25, p50 y p75)**: Los cuartiles dividen los datos en cuatro partes iguales, cada una representando el 25% de los datos. El cuartil 50 (p50) es la mediana, que indica el valor que separa los datos en dos partes iguales.

**Histograma**: El histograma proporciona una representación visual de la distribución de los datos. Permite identificar patrones, tendencias y características destacadas de la distribución de la variable.

Al analizar estos estadísticos para nuestras variables numéricas, podemos obtener una comprensión completa de su distribución y variabilidad. Buscamos patrones o tendencias significativas, así como valores atípicos que puedan influir en nuestros análisis posteriores.

```{r echo=FALSE, warning=FALSE}
datos <- datos |>
  mutate(
    store      = as.character(store),
    Visibility = as.character(Visibility),
    PedCount   = as.character(PedCount),
    Res        = as.character(Res),
    Hours24    = as.character(Hours24)
  )

```

```{r echo=FALSE, warning=FALSE}

# Gráficos de barras para las variables categóricas
plot1 <- ggplot(datos, aes(x = Visibility)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Frecuencia de Visibility", x = "Visibility", y = "")

plot2 <- ggplot(datos, aes(x = PedCount)) +
  geom_bar(fill = "lightgreen", color = "black") +
  labs(title = "Frecuencia de PedCount", x = "PedCount", y = "")

plot3 <- ggplot(datos, aes(x = Res)) +
  geom_bar(fill = "orange", color = "black") +
  labs(title = "Frecuencia de Res", x = "Res", y = "")

plot4 <- ggplot(datos, aes(x = Hours24)) +
  geom_bar(fill = "lightpink", color = "black") +
  labs(title = "Frecuencia de Hours24", x = "Hours24", y = "")

# Organizar los gráficos en un lienzo de 2 filas por 2 columnas
grid.arrange(plot1, plot2, plot3, plot4, nrow = 2, ncol = 2)

```

**Visibilidad**:

- La mayoría de las tiendas tienen una visibilidad alta (4 o 5).
- Hay algunas tiendas con una visibilidad baja (1 o 2).

**Tráfico peatonal**:

- La mayoría de las tiendas tienen un tráfico peatonal medio (3).
- Hay algunas tiendas con un tráfico peatonal alto (4 o 5) y bajo (1 o 2).


**Horario de apertura**:

- La mayoría de las tiendas no abren las 24 horas (0).
- Hay algunas tiendas que sí abren las 24 horas (1).


**Ubicación**:

- La mayoría de las tiendas están ubicadas en zonas residenciales (1).
- Hay algunas tiendas que están ubicadas en zonas industriales (0).


### Visualización de la relación existe entre las variables

Procederé a realizar algunas visualizaciones con el fin de obtener una comprensión intuitiva de la relación que pueda existir entre el beneficio (Profit) y algunas variables presentes en el conjunto de datos.

```{r echo=FALSE, warning=FALSE}



# Gráficos de puntos para las combinaciones de variables
plot1 <- ggplot(datos, aes(x = Sales, y = Profit)) +
  geom_point(color = "blue") +
  labs(title = "Profit Vs Sales", x = "Sales", y = "Profit")

plot2 <- ggplot(datos, aes(x = Comp, y = Profit)) +
  geom_point(color = "green") +
  labs(title = "Profit vs Comp", x = "Comp", y = "Profit")

plot3 <- ggplot(datos, aes(x = PedCount, y = Profit)) +
  geom_point(color = "red") +
  labs(title = "Profit vs PedCount", x = "PEdCount", y = "Profit")

plot4 <- ggplot(datos, aes(x = MgrSkill, y = Profit)) +
  geom_point(color = "purple") +
  labs(title = "Profit vs MgrSkill", x = "MgrSkill", y = "Profit")

plot5 <- ggplot(datos, aes(x = ServQual, y = Profit)) +
  geom_point(color = "purple") +
  labs(title = "Profit vs ServQual", x = "ServQual", y = "Profit")

# Organizar los gráficos en un lienzo de 2 filas por 2 columnas
grid.arrange(plot1, plot2, plot3, plot4, plot5, nrow = 2, ncol = 3)
```


Estas visualizaciones muestran cómo algunas variables seleccionadas se relacionan con Profit. Observamos que:

- **Sales vs Profit**: Hay una tendencia clara que un aumento en las ventas está asociado con un aumento en las ganancias.

- **Comp (Competencia) vs Profit**: A medida que el nivel de competencia aumenta, hay una tendencia a disminuir las ganancias, aunque la relación no parece ser tan fuerte.

- **PedCount (Conteo de Peatones) vs Profit**: Existe cierta tendencia positiva, indicando que un mayor tráfico peatonal podría estar relacionado con mayores ganancias.

- **MgrSkill (Habilidad del Gerente) vs Profit**: Se observa una relación positiva moderada, sugiriendo que las habilidades de gestión más altas pueden estar asociadas con mejores ganancias.

- **ServQual (Calidad del Servicio) vs Profit**: También se observa una relación positiva, indicando que una mejor calidad del servicio puede contribuir a mayores ganancias.


### Boxplot de Profit y Sales para las variables Hours24 y Visibility

```{r echo=FALSE, warning=FALSE}
plot10 <- ggplot(datos, aes(x = Hours24, y = Profit)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Boxplot de Profit por Hours24", x = "Hours24", y = "") +
  theme_classic()

plot20 <- ggplot(datos, aes(x = Visibility, y = Profit)) +
  geom_boxplot(fill = "green", color = "black") +
  labs(title = "Boxplot de Profit por Visibility ", x = "Visibility", y = "") +
  theme_classic()

plot30 <- ggplot(datos, aes(x = Hours24, y = Sales)) +
  geom_boxplot(fill = "red", color = "black") +
  labs(title = "Boxplot de Ventas por Hours24", x = "Hours24", y = "") +
  theme_classic()

plot40 <- ggplot(datos, aes(x = Visibility, y = Sales)) +
  geom_boxplot(fill = "purple", color = "black") +
  labs(title = "Boxplot de Sales por Visibility", x = "Visibility", y = "") +
  theme_classic()



# Organizar los gráficos en un lienzo de 2 filas por 2 columnas
grid.arrange(plot10, plot20, plot30, plot40, nrow = 2, ncol = 2)

```

Los gráficos de caja y bigotes revelan patrones interesantes en relación con el desempeño de las tiendas. Es notable que las tiendas que operan las 24 horas del día exhiben tanto un beneficio más alto como mayores ventas en comparación con las tiendas que tienen un horario de apertura estándar. Este hallazgo sugiere una correlación entre la disponibilidad continua y el éxito financiero de las tiendas.

Además, al observar la visibilidad de las tiendas, destacamos que aquellas que recibieron una calificación perfecta de 5 muestran un desempeño sobresaliente en términos de ganancias y ventas. Estas tiendas con una visibilidad excepcional experimentan un incremento significativo en sus ingresos en comparación con las tiendas que recibieron calificaciones más bajas. Esto sugiere una relación positiva entre la visibilidad del frente de la tienda y su rendimiento financiero, lo que subraya la importancia de una ubicación estratégica y una presentación visual atractiva para impulsar el éxito comercial.


### Beneficio y Ventas por tipo de zona

```{r echo=FALSE, warning=FALSE}
plot11 <- ggplot(datos, aes(x = Res, y = Profit)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Profit por Zona Residencial", x = "Res", y = "") +
  theme_classic()

plot12 <- ggplot(datos, aes(x = Res, y = Sales)) +
  geom_boxplot(fill = "green", color = "black") +
  labs(title = "Ventas por Zona Residencial", x = "Res", y = "") +
  theme_classic()

# Organizar los gráficos en un lienzo de 1 fila por 2 columnas
grid.arrange(plot11, plot12, nrow = 1, ncol = 2, widths = c(0.2, 0.2))


```


Al analizar los gráficos previos, se evidencia que la variabilidad de las ventas y las ganancias en las tiendas situadas en zonas residenciales es considerablemente menor en comparación con las tiendas ubicadas en áreas industriales. Por otro lado, las tiendas en zonas industriales exhiben una variabilidad más alta, lo que indica una mayor sensibilidad a factores externos o una mayor diversidad en los patrones de consumo en estas áreas


### Mapa de correlación

Un mapa de correlación es una herramienta visual poderosa que nos permite explorar las relaciones entre variables en un conjunto de datos. Esta representación gráfica nos proporciona una visión general de cómo las diferentes variables están relacionadas entre sí, mostrando la fuerza y la dirección de las asociaciones. Los coeficientes de correlación se representan mediante colores o mediante un código de colores, lo que facilita la identificación de patrones y tendencias en los datos. Este análisis es fundamental en la exploración de datos y en la identificación de posibles relaciones significativas que puedan influir en nuestro análisis o en la toma de decisiones.

```{r echo=FALSE, warning=FALSE}

# Seleccionar solo las columnas numéricas y excluir "store"
datos_numericos <- subset(datos, select = -c(store, Visibility,	PedCount,	Res,	Hours24))

# Calcular la matriz de correlación redondeada
correlacion <- round(cor(datos_numericos), 1)

# Crear el mapa de correlación con corrplot y ajustar el tamaño de los números
corrplot(correlacion, method = "number", type = "upper", tl.cex = 0.8, tl.col = "black", number.cex = 0.7)
```

- Hay una fuerte correlación positiva entre el beneficio y las ventas (Profit ~ Sales).
- Hay una correlación positiva débil entre el beneficios y la antigüedad en el puesto del gerente (Profit ~ MTenure).
- Hay una correlación positiva débil entre el beneficio y la calidad del servicio (Profit ~ SerQual).
- Hay una correlación negativa débil entre el beneficio y la competencia (Profit ~ Comp).
- Hay una correlación positiva débil entre la antigüedad en el puesto del personal y la habilidad del equipo (CTenure ~ CrewSkill).
- Hay una correlación positiva débil entre la antigüedad en el puesto del gerente y la habilidad en la gestión (MTenure ~ MgrSkill).



### Valores atípicos

Los valores atípicos, también conocidos como valores extremos o anomalías, son observaciones que se desvían significativamente del patrón general del conjunto de datos. En el contexto de la regresión lineal, los valores atípicos pueden tener un impacto considerable en la precisión y la interpretación del modelo. Por lo tanto, es fundamental estudiar y comprender la presencia de valores atípicos en el análisis de regresión, por ello se presentará un cuadro donde se indican cuántos ***Outliers*** hay presente en cada variable numérica:

```{r echo=FALSE, warning=FALSE}

# Calcula los extremos del bigote para cada variable
outliers_count <- data.frame(Variable = character(), Outliers_Count = numeric())

for (variable in colnames(datos)) {
  if (is.numeric(datos[[variable]]) && variable != "store") {
    boxplot_stats <- boxplot.stats(datos[[variable]])
    lower_whisker <- boxplot_stats$stats[1]
    upper_whisker <- boxplot_stats$stats[5]
    
    outliers <- datos[[variable]][datos[[variable]] < lower_whisker | datos[[variable]] > upper_whisker]
    outliers_count <- rbind(outliers_count, data.frame(Variable = variable, Valores_Atípicos = length(outliers)))
  }
}

# Mostrar la tabla con formato kable
kable(outliers_count, caption = "Conteo de valores atípicos por variable")
```

### Estandarizacion de los datos 

Considerando la presencia de valores atípicos importantes en nuestros datos financieros y su potencial relevancia para nuestro análisis, haré uso de la estandarización como método de preprocesamiento de datos. La estandarización es menos sensible a los valores atípicos en comparación con la normalización, ya que utiliza la media y la desviación estándar de los datos para centrar y escalar las características. Esto significa que los valores atípicos tienen menos influencia en la escala de las características estandarizadas, lo que puede ayudar a mitigar su impacto en nuestro modelo de regresión lineal múltiple. Además, la estandarización facilita una interpretación más clara de los coeficientes del modelo, ya que representan el cambio en la variable de respuesta en términos de desviaciones estándar de las características correspondientes.

```{r echo=FALSE, warning=FALSE}
# Obtener las columnas numéricas
columnas_numericas <- datos |>
  select(where(is.numeric)) |>
  colnames()

# Estandarizar las columnas numéricas
datos_estandarizados <- datos |>
  mutate(across(all_of(columnas_numericas), scale))

```
### Creación del modelo

Para construir el modelo de regresión lineal, utilizaré la función lm() del paquete stats de R. Esta función nos permitirá crear el modelo y obtener una visión detallada de cómo se comporta el mismo. A través de lm(), podremos ajustar el modelo a nuestros datos y examinar los coeficientes de regresión, los residuos, así como otras métricas de evaluación que nos ayudarán a comprender la relación entre las variables predictoras y la variable de respuesta.


```{r echo=FALSE, warning=FALSE}
# Establecer semilla para reproducibilidad
set.seed(123)

# Crear partición estratificada
particion <- createDataPartition(datos_estandarizados$Profit, p = 0.8, list = FALSE)

# Crear conjuntos de entrenamiento y prueba
datos_entrenamiento <- datos_estandarizados[particion, ]
datos_prueba <- datos_estandarizados[-particion, ]

# Separar las variables predictoras (X) y la variable objetivo (y)
X_entrenamiento <- datos_entrenamiento[, !(names(datos_entrenamiento) %in% "Profit")]
y_entrenamiento <- datos_entrenamiento[, "Profit", drop = FALSE] 
X_prueba <- datos_prueba[, !(names(datos_prueba) %in% "Profit")]
y_prueba <- datos_prueba$Profit


# Ajustar el modelo
modelo <- lm(data = cbind(X_entrenamiento, y_entrenamiento), formula = Profit ~ Sales + MTenure + CTenure + Pop + Comp +  CrewSkill + MgrSkill + ServQual)


# Predecir utilizando el modelo
y_pred <- predict(modelo, newdata = X_prueba)

# Calcular RMSE
rmse <- sqrt(mean((y_prueba - y_pred)^2))

# Calcular R²
r2 <- cor(y_pred, y_prueba)^2

# Crear un data frame con los resultados
resultados <- data.frame(
  "Métrica" = c("RMSE (Error Cuadrático Medio Raíz)", "R² (Coeficiente de Determinación)"),
  "Valor" = c(rmse, r2)
)

# Formatear la tabla con knitr::kable
tabla_resultados <- knitr::kable(resultados, align = "c")

# Imprimir la tabla
print(tabla_resultados)

# Obtener los coeficientes del modelo
coeficientes <- coef(modelo)

# Crear un dataframe con los coeficientes
df_coeficientes <- data.frame(
  "Variable" = names(coeficientes),
  "Coeficiente" = coeficientes
)

# Formatear la tabla con kable
tabla_coeficientes <- knitr::kable(df_coeficientes, align = "c", caption = "Coeficientes del Modelo de Regresión")

# Imprimir la tabla
print(tabla_coeficientes)

```


```{r echo=FALSE, warning=FALSE}
# Gráfico de los coeficientes

# Extraer los coeficientes del modelo
coeficientes <- coef(modelo)[-1]  # Excluyendo el intercepto

# Crear un dataframe con los nombres de las variables y los coeficientes
coeficientes_df <- data.frame(Variable = names(coeficientes), Coeficiente = coeficientes)

# Ordenar el dataframe por los valores de los coeficientes
coeficientes_df <- coeficientes_df[order(coeficientes_df$Coeficiente), ]

# Crear el gráfico de barras
grafico_coefs <- ggplot(coeficientes_df, aes(x = reorder(Variable, Coeficiente), y = Coeficiente, fill = ifelse(Coeficiente > 0, "Positivo", "Negativo"))) +
  geom_bar(stat = "identity") +
  labs(title = "Coeficientes del Modelo de Regresión Lineal",
       x = "Variable",
       y = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # Rotar etiquetas del eje x
  scale_fill_manual(values = c("Positivo" = "skyblue", "Negativo" = "red")) +  # Asignar colores
  guides(fill = FALSE)
# Mostrar el gráfico
print(grafico_coefs)


```

### Resumen del Modelo

```{r echo=FALSE, warning=FALSE}
# Obtener el resumen del modelo
summary_modelo <- summary(modelo)

# Extraer los coeficientes y los p-values
coeficientes <- summary_modelo$coefficients[, 1]
p_values <- summary_modelo$coefficients[, 4]

# Calcular el número de asteriscos basado en el valor absoluto del logaritmo negativo del p-value
num_asteriscos <- floor(-log10(p_values))

# Asegurarnos de que num_asteriscos sea un número entero positivo
num_asteriscos <- pmax(num_asteriscos, 0)

# Crear un vector de asteriscos
asteriscos <- ifelse(num_asteriscos > 0, paste(rep("*", max(num_asteriscos)), collapse = ""), "")

# Crear un dataframe con los coeficientes, los p-values y los asteriscos
df_coeficientes <- data.frame(
  "Variable" = rownames(summary_modelo$coefficients),
  "Coeficiente" = coeficientes,
  "P-value" = p_values,
  "Significancia" = asteriscos
)

# Imprimir el dataframe
print(df_coeficientes)

```

### Interpretación de los resultados
- **RMSE (Error Cuadrático Medio Raíz):** Un valor de RMSE de 0.3854082 indica que, en promedio, las predicciones del modelo están desviadas por aproximadamente 0.3854082 unidades de la variable objetivo. Dado que la variable objetivo oscila entre -1.724011 y 2.71446, un RMSE de esta magnitud podría considerarse aceptable, especialmente si se tiene en cuenta la escala y la variabilidad de la variable objetivo.

- **R² (Coeficiente de Determinación):** Un valor de R² de 0.8840036 sugiere que el modelo explica aproximadamente el 88.4% de la variabilidad en la variable objetivo. Esto indica que el modelo tiene una capacidad predictiva considerable y puede explicar una cantidad significativa de la variabilidad en los datos observados.

En resumen, los resultados sugieren que el modelo tiene un buen desempeño en la predicción de la variable objetivo y puede ser útil para comprender y predecir el comportamiento de la variable objetivo en función de las variables predictoras incluidas en el modelo. 





### Variables significativas

En nuestro análisis, la variable Sales emerge como la más significativa, seguida, aunque no de manera inmediata, por MTenure (Antigüedad en el puesto del gerente), cuyo impacto resulta ser bastante tenue. Por otro lado, la variable Comp (competidores) muestra una relación inversa con las ganancias, indicando que una mayor competencia se correlaciona con menores ganancias. Sin embargo, estas observaciones, aunque reveladoras, no proporcionan una respuesta completa a nuestra pregunta inicial. Es posible que otras variables no consideradas en nuestro análisis puedan desempeñar un papel crucial en las ganancias de las tiendas.

Para profundizar en esta investigación, proponemos varias vías de análisis adicionales:

1. **Análisis de Interacción:** Explorar si la combinación de variables, como antigüedad en el puesto del gerente y la habilidad de gestión, tiene un efecto sinérgico en las ganancias. Este enfoque podría revelar si las tiendas con un gerente con varios años de servicio obtienen un mayor beneficio que aquellas con gerente sin.

2. **Análisis de Subgrupos:** Investigar cómo estas variables afectan las ganancias en diferentes contextos, como ubicaciones específicas o tiendas de diferentes tamaños. Esto podría proporcionar información sobre si la importancia de la habilidad del gerente varía según el entorno.

3. **Importancia Relativa:** Emplear técnicas estadísticas para evaluar la importancia relativa de las variables en la predicción de ganancias. Este análisis arrojaría luz sobre cuánto contribuye cada factor al éxito financiero de las tiendas.

Al profundizar de esta manera, podemos obtener una comprensión más completa de los factores que influyen en las ganancias de las tiendas y desarrollar estrategias más efectivas para optimizar el rendimiento financiero.


### Añadir un término de interacción al DataFrame

En el análisis de regresión lineal, la construcción de modelos precisos y representativos es esencial para comprender las relaciones entre las variables predictoras y la variable de respuesta. Una técnica poderosa para mejorar la capacidad predictiva de un modelo es la creación de variables de interacción.

Las variables de interacción son productos entre dos o más variables predictoras y pueden capturar efectos conjuntos que no se pueden capturar considerando las variables por separado. Esta técnica es particularmente útil cuando se sospecha que las relaciones entre las variables predictoras y la variable de respuesta son no lineales o cuando ciertas variables tienen un efecto modificador en otras.

Para nuestro estudio, nos centramos en el beneficio (Profit) de una empresa y cómo está influenciado por diversas variables, incluyendo la antigüedad en el puesto (MTenure y CTenure) y las habilidades del personal y los gerentes (CrewSkill y MgrSkill). Es crucial entender cómo la experiencia acumulada del personal y los gerentes interactúa con sus habilidades respectivas para influir en el rendimiento de la empresa.

Por tanto, hemos creado dos nuevas variables de interacción:

1. **Interacción entre CTenure y CrewSkill:** Esta variable captura cómo la antigüedad en el puesto del personal interactúa con sus habilidades. Es interesante observar cómo la experiencia acumulada del personal se relaciona con sus habilidades para influir en el beneficio de la empresa.

2. **Interacción entre MTenure y MgrSkill:** Esta variable refleja cómo la antigüedad en el puesto de los gerentes interactúa con sus habilidades. Observar cómo la experiencia acumulada de los gerentes se relaciona con sus habilidades puede proporcionar información valiosa sobre su impacto en el rendimiento financiero de la empresa.

La inclusión de estas nuevas variables de interacción en nuestro modelo de regresión lineal nos permitirá examinar cómo la experiencia y las habilidades conjuntas del personal y los gerentes afectan al beneficio de la empresa. Su significancia estadística y su impacto en la predicción del beneficio nos ayudarán a obtener una comprensión más completa de los factores que influyen en el éxito financiero de la empresa.

```{r, echo=FALSE, warning=FALSE} 
# Copio el Datframe
datos2 <- datos

# Crear las dos nuevas variable 
datos2 <- datos2 |>
  mutate(
    interaccion_CTenure_CrewSkill = CTenure * CrewSkill,
    interaccion_MTenure_MgrSkill  = MTenure * MgrSkill
  ) |> 
  select(c(Sales, Profit, MTenure, CTenure, Pop, Comp, CrewSkill, MgrSkill, ServQual, interaccion_CTenure_CrewSkill, interaccion_MTenure_MgrSkill  )) |>
  scale() |>
  as.data.frame()

# División del conjunto de datos


# Establecer semilla para reproducibilidad
set.seed(123)

# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)
indice_entrenamiento <- createDataPartition(datos2$Profit, p = 0.8, list = FALSE)

datos2_entrenamiento <- datos2[indice_entrenamiento, ]
datos2_prueba <- datos2[-indice_entrenamiento, ]

# Separar las variables predictoras (X) y la variable objetivo (y)
X2_entrenamiento <- datos2_entrenamiento[, !(names(datos2_entrenamiento) %in% "Profit")]
y2_entrenamiento <- datos2_entrenamiento[, "Profit", drop = FALSE] 
X2_prueba <- datos2_prueba[, !(names(datos2_prueba) %in% "Profit")]
y2_prueba <- datos2_prueba$Profit

# Ver las dimensiones de los conjuntos de entrenamiento y prueba
dim(datos2_entrenamiento)
dim(datos2_prueba)


# Ajustar el modelo
modelo2 <- lm(data = cbind(X2_entrenamiento, y2_entrenamiento), formula = Profit ~ Sales + MTenure + CTenure + Pop + Comp +  CrewSkill + MgrSkill + ServQual +  interaccion_MTenure_MgrSkill )


# Predecir utilizando el modelo
y2_pred <- predict(modelo2, newdata = X2_prueba)

# Calcular RMSE
rmse2 <- sqrt(mean((y2_prueba - y2_pred)^2))

# Calcular R²
r2 <- cor(y2_pred, y2_prueba)^2

# Crear un data frame con los resultados
resultados2 <- data.frame(
  "Métrica" = c("RMSE (Error Cuadrático Medio Raíz)", "R² (Coeficiente de Determinación)"),
  "Valor" = c(rmse2, r2)
)

# Formatear la tabla con knitr::kable
tabla2_resultados <- knitr::kable(resultados2, align = "c")

# Imprimir la tabla
print(tabla2_resultados)

# Obtener los coeficientes del modelo
coeficientes2 <- coef(modelo2)

# Crear un dataframe con los coeficientes
df2_coeficientes <- data.frame(
  "Variable" = names(coeficientes2),
  "Coeficiente" = coeficientes2
)

# Formatear la tabla con kable
tabla2_coeficientes <- knitr::kable(df2_coeficientes, align = "c", caption = "Coeficientes del Modelo de Regresión")

# Imprimir la tabla
print(tabla2_coeficientes)

```


```{r echo=FALSE, warning=FALSE}
# Gráfico de los coeficientes

# Extraer los coeficientes del modelo
coeficientes2 <- coef(modelo2)[-1]  # Excluyendo el intercepto

# Crear un dataframe con los nombres de las variables y los coeficientes
coeficientes2_df <- data.frame(Variable = names(coeficientes2), Coeficiente = coeficientes2)

# Ordenar el dataframe por los valores de los coeficientes
coeficientes2_df <- coeficientes2_df[order(coeficientes2_df$Coeficiente), ]

# Crear el gráfico de barras
grafico2_coefs <- ggplot(coeficientes2_df, aes(x = reorder(Variable, Coeficiente), y = Coeficiente, fill = ifelse(Coeficiente > 0, "Positivo", "Negativo"))) +
  geom_bar(stat = "identity") +
  labs(title = "Coeficientes del Modelo de Regresión Lineal",
       x = "Variable",
       y = "") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotar etiquetas del eje x
  scale_fill_manual(values = c("Positivo" = "skyblue", "Negativo" = "red")) +  # Asignar colores
  guides(fill = FALSE)  # Eliminar la leyenda

# Mostrar el gráfico
print(grafico2_coefs)

```


Para este modelo, se ha incorporado una nueva variable que es el producto de MTenure (Antigüedad en el puesto del gerente) y MgrSkill (habilidad de gestión). Es notable observar que esta nueva variable resulta altamente significativa en nuestro análisis. Esto sugiere que la combinación de la antigüedad en el puesto del gerente y su habilidad de gestión puede desempeñar un papel crucial en el resultado de nuestras ganancias. Este hallazgo amplía nuestra comprensión de los factores que influyen en el rendimiento de las tiendas, y subraya la importancia de considerar interacciones entre variables en futuros análisis










### Cálculo de bonificación para un gerente que presenta los sguientes datos en su tiienda

|    | store |    Sales   |   Profit   |  MTenure  |  CTenure  |   Pop   |   Comp   | CrewSkill | MgrSkill | ServQual |
|----|-------|------------|------------|-----------|-----------|---------|----------|-----------|----------|----------|
| 1  |   9   | 2113089    | 474725     | 108.9935  | 6.061602  | 26519   | 2.63763  | 3.22      | 3.583333 | 100      |
| 2  |   9   | 2747015.7  | 901977.5   | 130.7922  | 7.2739224 | 26519   | 2.63763  | 3.22      | 3.583333 | 100      |


```{r echo=FALSE, warning=FALSE}
# Crear un data frame con los datos proporcionados
datos6 <- data.frame(
  store = c(9, 9),
  Sales = c(2113089, 2747015.7),
  Profit = c(474725, 901977.5),
  MTenure = c(108.9935, 115.53311),
  CTenure = c(6.061602, 7.2739224),
  Pop = c(26519, 26519),
  Comp = c(2.63763, 2.63763),
  CrewSkill = c(3.22, 3.22),
  MgrSkill = c(3.583333, 3.583333),
  ServQual = c(100, 100)
)

# Calcular la variable de interacción correctamente
datos6$interaccion_MTenure_MgrSkill <- datos6$MTenure * datos6$MgrSkill

# Aumentar en 0.5 años el valor de MTenure en el segundo conjunto de datos
datos6$nueva_MTenure <- ifelse(datos6$store == 9, datos6$MTenure + 0.5, datos6$MTenure)

# Aumentar la variable de interacción en consecuencia
datos6$nueva_interaccion_MTenure_MgrSkill <- ifelse(datos6$store == 9, datos6$interaccion_MTenure_MgrSkill + 0.5 * datos6$MgrSkill, datos6$interaccion_MTenure_MgrSkill)

# Realizar la predicción de las ganancias con el nuevo conjunto de datos
prediccion_ganancias <- predict(modelo2, newdata = datos6)

# Calcular el cambio en las ganancias para la tienda que aumentó sus años de servicio
cambio_ganancias_gerente <- prediccion_ganancias[2] - prediccion_ganancias[1]

# Definir la proporción de bonificación (por ejemplo, 10%)
proporcion_bonificacion <- 0.10

# Calcular la bonificación específica para el gerente de la tienda
bonificacion_gerente <- cambio_ganancias_gerente * proporcion_bonificacion

# Mostrar la bonificación específica para el gerente de la tienda
print(bonificacion_gerente)
```
### Resultado de la aplicación del modelo:
La estimación de las ganacias en la tienda 9 bajo estos nuevos parámetros es de 49.349,73 y el promedio de los meses de servicios del gerente aumentó en 6.6 meses en promedio, con este valor puede estimarse una bonificación al gerente.
